#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åŒçŸ¥è¯†åº“ç³»ç»Ÿ
é€šç”¨çŸ¥è¯†åº“ï¼ˆUniversal KBï¼‰+ ä¸´æ—¶çŸ¥è¯†åº“ï¼ˆTemporary KBï¼‰

é€šç”¨çŸ¥è¯†åº“ï¼šå­˜å‚¨é€šç”¨ç­”é¢˜æŠ€å·§å’Œç»éªŒï¼ˆé•¿æœŸä¿ç•™ï¼‰
ä¸´æ—¶çŸ¥è¯†åº“ï¼šå­˜å‚¨å½“å‰é—®å·çš„ç‰¹å®šç»éªŒï¼ˆä»»åŠ¡å®Œæˆåæ¸…ç†ï¼‰
"""

import asyncio
import json
import logging
import time
import uuid
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Union
from dataclasses import dataclass, field
import sqlite3
import os

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class UniversalExperience:
    """é€šç”¨ç­”é¢˜ç»éªŒ"""
    experience_id: str
    question_type: str  # é¢˜ç›®ç±»å‹ï¼šå•é€‰ã€å¤šé€‰ã€å¡«ç©ºã€è¯„åˆ†ç­‰
    strategy: str  # ç­”é¢˜ç­–ç•¥
    success_pattern: str  # æˆåŠŸæ¨¡å¼
    failure_pattern: str  # å¤±è´¥æ¨¡å¼
    confidence_score: float  # å¯ä¿¡åº¦
    usage_count: int  # ä½¿ç”¨æ¬¡æ•°
    success_rate: float  # æˆåŠŸç‡
    created_at: str
    updated_at: str

@dataclass
class TemporaryExperience:
    """ä¸´æ—¶é—®å·ç»éªŒ"""
    experience_id: str
    questionnaire_url: str  # é—®å·URL
    question_content: str  # é¢˜ç›®å†…å®¹
    correct_answer: str  # æ­£ç¡®ç­”æ¡ˆ
    wrong_answers: List[str]  # é”™è¯¯ç­”æ¡ˆ
    answer_reasoning: str  # ç­”é¢˜ç†ç”±
    digital_human_id: str  # æ•°å­—äººID
    digital_human_profile: Dict  # æ•°å­—äººç‰¹å¾
    success: bool  # æ˜¯å¦æˆåŠŸ
    page_number: int  # é¡µé¢ç¼–å·
    timestamp: str

@dataclass
class QuestionnaireAnalysis:
    """é—®å·åˆ†æç»“æœ"""
    questionnaire_url: str
    target_audience: Dict  # ç›®æ ‡äººç¾¤
    question_patterns: List[Dict]  # é¢˜ç›®æ¨¡å¼
    trap_questions: List[Dict]  # é™·é˜±é¢˜ç›®
    success_strategies: List[str]  # æˆåŠŸç­–ç•¥
    recommended_answers: Dict  # æ¨èç­”æ¡ˆ
    analysis_confidence: float  # åˆ†æå¯ä¿¡åº¦
    generated_at: str

class DualKnowledgeBaseSystem:
    """åŒçŸ¥è¯†åº“ç³»ç»Ÿç®¡ç†å™¨"""
    
    def __init__(self, db_path: str = "knowledge_base.db"):
        self.db_path = db_path
        self.gemini_api_key = "AIzaSyAfmaTObVEiq6R_c62T4jeEpyf6yp4WCP8"
        
        # åˆå§‹åŒ–æ•°æ®åº“
        self._init_database()
        
        # åˆå§‹åŒ–Geminiï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import google.generativeai as genai
            genai.configure(api_key=self.gemini_api_key)
            self.model = genai.GenerativeModel("gemini-2.0-flash")
            self.gemini_available = True
            logger.info("âœ… Gemini API åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.warning(f"âš ï¸ Gemini API ä¸å¯ç”¨: {e}")
            self.model = None
            self.gemini_available = False
        
        logger.info("âœ… åŒçŸ¥è¯†åº“ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¡¨ç»“æ„"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # é€šç”¨çŸ¥è¯†åº“è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS universal_experiences (
                    experience_id TEXT PRIMARY KEY,
                    question_type TEXT NOT NULL,
                    strategy TEXT NOT NULL,
                    success_pattern TEXT,
                    failure_pattern TEXT,
                    confidence_score REAL DEFAULT 0.0,
                    usage_count INTEGER DEFAULT 0,
                    success_rate REAL DEFAULT 0.0,
                    created_at TEXT NOT NULL,
                    updated_at TEXT NOT NULL
                )
            ''')
            
            # ä¸´æ—¶çŸ¥è¯†åº“è¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS temporary_experiences (
                    experience_id TEXT PRIMARY KEY,
                    questionnaire_url TEXT NOT NULL,
                    question_content TEXT NOT NULL,
                    correct_answer TEXT,
                    wrong_answers TEXT,  -- JSONæ ¼å¼
                    answer_reasoning TEXT,
                    digital_human_id TEXT NOT NULL,
                    digital_human_profile TEXT,  -- JSONæ ¼å¼
                    success BOOLEAN NOT NULL,
                    page_number INTEGER DEFAULT 1,
                    timestamp TEXT NOT NULL
                )
            ''')
            
            # ä¸ºä¸´æ—¶çŸ¥è¯†åº“è¡¨åˆ›å»ºç´¢å¼•
            cursor.execute('''
                CREATE INDEX IF NOT EXISTS idx_temporary_experiences_url 
                ON temporary_experiences(questionnaire_url)
            ''')
            
            # é—®å·åˆ†æè¡¨
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS questionnaire_analyses (
                    questionnaire_url TEXT PRIMARY KEY,
                    target_audience TEXT,  -- JSONæ ¼å¼
                    question_patterns TEXT,  -- JSONæ ¼å¼
                    trap_questions TEXT,  -- JSONæ ¼å¼
                    success_strategies TEXT,  -- JSONæ ¼å¼
                    recommended_answers TEXT,  -- JSONæ ¼å¼
                    analysis_confidence REAL DEFAULT 0.0,
                    generated_at TEXT NOT NULL
                )
            ''')
            
            conn.commit()
            conn.close()
            
            logger.info("âœ… æ•°æ®åº“è¡¨ç»“æ„åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    async def save_temporary_experience(self, experience: TemporaryExperience) -> bool:
        """ä¿å­˜ä¸´æ—¶é—®å·ç»éªŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO temporary_experiences 
                (experience_id, questionnaire_url, question_content, correct_answer, 
                 wrong_answers, answer_reasoning, digital_human_id, digital_human_profile, 
                 success, page_number, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                experience.experience_id,
                experience.questionnaire_url,
                experience.question_content,
                experience.correct_answer,
                json.dumps(experience.wrong_answers, ensure_ascii=False),
                experience.answer_reasoning,
                experience.digital_human_id,
                json.dumps(experience.digital_human_profile, ensure_ascii=False),
                experience.success,
                experience.page_number,
                experience.timestamp
            ))
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… ä¸´æ—¶ç»éªŒå·²ä¿å­˜: {experience.experience_id}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ä¸´æ—¶ç»éªŒå¤±è´¥: {e}")
            return False
    
    async def get_temporary_experiences(self, questionnaire_url: str) -> List[TemporaryExperience]:
        """è·å–æŒ‡å®šé—®å·çš„ä¸´æ—¶ç»éªŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM temporary_experiences 
                WHERE questionnaire_url = ?
                ORDER BY timestamp DESC
            ''', (questionnaire_url,))
            
            rows = cursor.fetchall()
            conn.close()
            
            experiences = []
            for row in rows:
                experience = TemporaryExperience(
                    experience_id=row[0],
                    questionnaire_url=row[1],
                    question_content=row[2],
                    correct_answer=row[3],
                    wrong_answers=json.loads(row[4]) if row[4] else [],
                    answer_reasoning=row[5],
                    digital_human_id=row[6],
                    digital_human_profile=json.loads(row[7]) if row[7] else {},
                    success=bool(row[8]),
                    page_number=row[9],
                    timestamp=row[10]
                )
                experiences.append(experience)
            
            logger.info(f"âœ… è·å–åˆ° {len(experiences)} æ¡ä¸´æ—¶ç»éªŒ")
            return experiences
            
        except Exception as e:
            logger.error(f"âŒ è·å–ä¸´æ—¶ç»éªŒå¤±è´¥: {e}")
            return []
    
    async def analyze_questionnaire_with_gemini(
        self, 
        questionnaire_url: str, 
        temporary_experiences: List[TemporaryExperience]
    ) -> Optional[QuestionnaireAnalysis]:
        """ä½¿ç”¨Geminiåˆ†æé—®å·ï¼Œç”Ÿæˆæ™ºèƒ½æŒ‡å¯¼"""
        if not self.gemini_available:
            return await self._create_mock_analysis(questionnaire_url, temporary_experiences)
        
        try:
            # åˆ†ç¦»æˆåŠŸå’Œå¤±è´¥çš„ç»éªŒ
            successful_experiences = [exp for exp in temporary_experiences if exp.success]
            failed_experiences = [exp for exp in temporary_experiences if not exp.success]
            
            # æ„å»ºåˆ†ææç¤ºè¯
            analysis_prompt = self._build_analysis_prompt(
                questionnaire_url, successful_experiences, failed_experiences
            )
            
            # è°ƒç”¨Geminiè¿›è¡Œåˆ†æ
            logger.info("ğŸ§  è°ƒç”¨Geminiè¿›è¡Œé—®å·æ™ºèƒ½åˆ†æ...")
            response = await self.model.generate_content_async(analysis_prompt)
            
            # è§£æåˆ†æç»“æœ
            analysis = self._parse_gemini_analysis_response(
                questionnaire_url, response.text
            )
            
            # ä¿å­˜åˆ†æç»“æœ
            await self._save_questionnaire_analysis(analysis)
            
            logger.info("âœ… Geminiåˆ†æå®Œæˆ")
            return analysis
            
        except Exception as e:
            logger.error(f"âŒ Geminiåˆ†æå¤±è´¥: {e}")
            # é™çº§åˆ°æ¨¡æ‹Ÿåˆ†æ
            return await self._create_mock_analysis(questionnaire_url, temporary_experiences)
    
    def _build_analysis_prompt(
        self, 
        questionnaire_url: str, 
        successful_experiences: List[TemporaryExperience],
        failed_experiences: List[TemporaryExperience]
    ) -> str:
        """æ„å»ºGeminiåˆ†ææç¤ºè¯"""
        
        prompt = f"""
ä½ æ˜¯ä¸“ä¸šçš„é—®å·åˆ†æä¸“å®¶ï¼Œè¯·å¯¹ä»¥ä¸‹é—®å·è¿›è¡Œæ·±åº¦æ™ºèƒ½åˆ†æï¼š

ğŸ“‹ é—®å·URL: {questionnaire_url}

ğŸ“Š æˆåŠŸç»éªŒæ•°æ® ({len(successful_experiences)}æ¡):
"""
        
        # æ·»åŠ æˆåŠŸç»éªŒ
        for i, exp in enumerate(successful_experiences[:10], 1):  # é™åˆ¶æ•°é‡é¿å…tokenè¿‡å¤š
            prompt += f"""
æˆåŠŸæ¡ˆä¾‹{i}:
- æ•°å­—äºº: {exp.digital_human_profile.get('name', 'æœªçŸ¥')} (å¹´é¾„{exp.digital_human_profile.get('age', 'æœªçŸ¥')}, {exp.digital_human_profile.get('job', 'æœªçŸ¥')})
- é¢˜ç›®: {exp.question_content[:100]}...
- æ­£ç¡®ç­”æ¡ˆ: {exp.correct_answer}
- ç­”é¢˜ç†ç”±: {exp.answer_reasoning}
- é¡µé¢: {exp.page_number}
"""
        
        prompt += f"""

âŒ å¤±è´¥ç»éªŒæ•°æ® ({len(failed_experiences)}æ¡):
"""
        
        # æ·»åŠ å¤±è´¥ç»éªŒ
        for i, exp in enumerate(failed_experiences[:5], 1):  # å¤±è´¥ç»éªŒæ•°é‡æ›´å°‘
            prompt += f"""
å¤±è´¥æ¡ˆä¾‹{i}:
- æ•°å­—äºº: {exp.digital_human_profile.get('name', 'æœªçŸ¥')} (å¹´é¾„{exp.digital_human_profile.get('age', 'æœªçŸ¥')}, {exp.digital_human_profile.get('job', 'æœªçŸ¥')})
- é¢˜ç›®: {exp.question_content[:100]}...
- é”™è¯¯ç­”æ¡ˆ: {exp.wrong_answers}
- å¤±è´¥åŸå› : {exp.answer_reasoning}
"""
        
        prompt += """

ğŸ¯ è¯·åˆ†æå¹¶è¾“å‡ºä»¥ä¸‹JSONæ ¼å¼ç»“æœï¼š

{
  "target_audience": {
    "age_range": "å¹´é¾„èŒƒå›´",
    "occupation": ["èŒä¸šç±»å‹"],
    "income_level": "æ”¶å…¥æ°´å¹³",
    "characteristics": ["äººç¾¤ç‰¹å¾"]
  },
  "question_patterns": [
    {
      "pattern_type": "é¢˜ç›®ç±»å‹",
      "description": "æ¨¡å¼æè¿°",
      "examples": ["ç¤ºä¾‹é¢˜ç›®"]
    }
  ],
  "trap_questions": [
    {
      "question": "é™·é˜±é¢˜ç›®",
      "trap_type": "é™·é˜±ç±»å‹",
      "correct_strategy": "æ­£ç¡®ç­–ç•¥"
    }
  ],
  "success_strategies": [
    "æˆåŠŸç­–ç•¥1",
    "æˆåŠŸç­–ç•¥2"
  ],
  "recommended_answers": {
    "age_preference": "å¹´é¾„åå¥½",
    "income_preference": "æ”¶å…¥åå¥½",
    "occupation_preference": "èŒä¸šåå¥½"
  },
  "analysis_confidence": 0.85
}

è¯·ç¡®ä¿åˆ†æç»“æœå‡†ç¡®ã€å®ç”¨ï¼Œèƒ½å¤ŸæŒ‡å¯¼åç»­çš„å¤§éƒ¨é˜Ÿä½œç­”ã€‚
        """
        
        return prompt
    
    def _parse_gemini_analysis_response(
        self, 
        questionnaire_url: str, 
        response_text: str
    ) -> QuestionnaireAnalysis:
        """è§£æGeminiåˆ†æå“åº”"""
        try:
            # æå–JSONéƒ¨åˆ†
            json_start = response_text.find('{')
            json_end = response_text.rfind('}') + 1
            
            if json_start == -1 or json_end == 0:
                raise ValueError("å“åº”ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆJSON")
            
            json_str = response_text[json_start:json_end]
            analysis_data = json.loads(json_str)
            
            return QuestionnaireAnalysis(
                questionnaire_url=questionnaire_url,
                target_audience=analysis_data.get('target_audience', {}),
                question_patterns=analysis_data.get('question_patterns', []),
                trap_questions=analysis_data.get('trap_questions', []),
                success_strategies=analysis_data.get('success_strategies', []),
                recommended_answers=analysis_data.get('recommended_answers', {}),
                analysis_confidence=analysis_data.get('analysis_confidence', 0.0),
                generated_at=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.warning(f"âš ï¸ è§£æGeminiå“åº”å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ")
            return self._create_default_analysis(questionnaire_url)
    
    async def _create_mock_analysis(
        self, 
        questionnaire_url: str, 
        temporary_experiences: List[TemporaryExperience]
    ) -> QuestionnaireAnalysis:
        """åˆ›å»ºæ¨¡æ‹Ÿåˆ†æç»“æœ"""
        successful_experiences = [exp for exp in temporary_experiences if exp.success]
        
        # åŸºäºå®é™…ç»éªŒç”Ÿæˆæ¨¡æ‹Ÿåˆ†æ
        target_audience = self._extract_target_audience(successful_experiences)
        question_patterns = self._extract_question_patterns(temporary_experiences)
        
        analysis = QuestionnaireAnalysis(
            questionnaire_url=questionnaire_url,
            target_audience=target_audience,
            question_patterns=question_patterns,
            trap_questions=[
                {
                    "question": "æ”¶å…¥éªŒè¯é¢˜ç›®",
                    "trap_type": "æ”¶å…¥èŒƒå›´ç­›é€‰",
                    "correct_strategy": "é€‰æ‹©ä¸­ç­‰æ”¶å…¥æ°´å¹³"
                }
            ],
            success_strategies=[
                "é€‰æ‹©ä¸­ç­‰å¹´é¾„æ®µ",
                "è¡¨ç°å‡ºé€‚ä¸­çš„æ¶ˆè´¹èƒ½åŠ›",
                "æ˜¾ç¤ºå¯¹äº§å“çš„å…´è¶£ä½†ä¸è¿‡åº¦çƒ­æƒ…"
            ],
            recommended_answers={
                "age_preference": "25-35å²",
                "income_preference": "5000-15000å…ƒ",
                "occupation_preference": "åŠå…¬å®¤èŒå‘˜æˆ–ä¸“ä¸šäººå‘˜"
            },
            analysis_confidence=0.75,
            generated_at=datetime.now().isoformat()
        )
        
        await self._save_questionnaire_analysis(analysis)
        return analysis
    
    def _extract_target_audience(self, successful_experiences: List[TemporaryExperience]) -> Dict:
        """ä»æˆåŠŸç»éªŒä¸­æå–ç›®æ ‡äººç¾¤ç‰¹å¾"""
        if not successful_experiences:
            return {
                "age_range": "25-35å²",
                "occupation": ["åŠå…¬å®¤èŒå‘˜"],
                "income_level": "ä¸­ç­‰",
                "characteristics": ["åŸå¸‚ç™½é¢†"]
            }
        
        # åˆ†ææˆåŠŸæ•°å­—äººçš„ç‰¹å¾
        ages = []
        occupations = []
        
        for exp in successful_experiences:
            profile = exp.digital_human_profile
            if 'age' in profile:
                try:
                    ages.append(int(profile['age']))
                except:
                    pass
            if 'job' in profile:
                occupations.append(profile['job'])
        
        # è®¡ç®—å¹´é¾„èŒƒå›´
        if ages:
            min_age = min(ages)
            max_age = max(ages)
            age_range = f"{min_age}-{max_age}å²"
        else:
            age_range = "25-35å²"
        
        # æå–èŒä¸šç±»å‹
        unique_occupations = list(set(occupations)) if occupations else ["åŠå…¬å®¤èŒå‘˜"]
        
        return {
            "age_range": age_range,
            "occupation": unique_occupations[:3],  # æœ€å¤š3ä¸ªèŒä¸š
            "income_level": "ä¸­ç­‰",
            "characteristics": ["ç›®æ ‡ç”¨æˆ·ç¾¤ä½“"]
        }
    
    def _extract_question_patterns(self, experiences: List[TemporaryExperience]) -> List[Dict]:
        """æå–é¢˜ç›®æ¨¡å¼"""
        patterns = []
        
        # æŒ‰é¡µé¢åˆ†ç»„
        pages = {}
        for exp in experiences:
            page_num = exp.page_number
            if page_num not in pages:
                pages[page_num] = []
            pages[page_num].append(exp)
        
        for page_num, page_experiences in pages.items():
            successful_count = sum(1 for exp in page_experiences if exp.success)
            total_count = len(page_experiences)
            
            patterns.append({
                "pattern_type": f"ç¬¬{page_num}é¡µé¢˜ç›®",
                "description": f"æˆåŠŸç‡: {successful_count}/{total_count}",
                "examples": [exp.question_content[:50] + "..." for exp in page_experiences[:3]]
            })
        
        return patterns
    
    def _create_default_analysis(self, questionnaire_url: str) -> QuestionnaireAnalysis:
        """åˆ›å»ºé»˜è®¤åˆ†æç»“æœ"""
        return QuestionnaireAnalysis(
            questionnaire_url=questionnaire_url,
            target_audience={
                "age_range": "25-35å²",
                "occupation": ["åŠå…¬å®¤èŒå‘˜", "ä¸“ä¸šäººå‘˜"],
                "income_level": "ä¸­ç­‰",
                "characteristics": ["åŸå¸‚æ¶ˆè´¹è€…"]
            },
            question_patterns=[
                {
                    "pattern_type": "åŸºç¡€ä¿¡æ¯é¢˜",
                    "description": "æ”¶é›†ç”¨æˆ·åŸºæœ¬ä¿¡æ¯",
                    "examples": ["å¹´é¾„é€‰æ‹©", "èŒä¸šé€‰æ‹©", "æ”¶å…¥æ°´å¹³"]
                }
            ],
            trap_questions=[],
            success_strategies=[
                "é€‰æ‹©ä¸­ç­‰é€‰é¡¹",
                "é¿å…æç«¯ç­”æ¡ˆ"
            ],
            recommended_answers={
                "age_preference": "25-35å²",
                "income_preference": "ä¸­ç­‰æ°´å¹³"
            },
            analysis_confidence=0.6,
            generated_at=datetime.now().isoformat()
        )
    
    async def _save_questionnaire_analysis(self, analysis: QuestionnaireAnalysis) -> bool:
        """ä¿å­˜é—®å·åˆ†æç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT OR REPLACE INTO questionnaire_analyses 
                (questionnaire_url, target_audience, question_patterns, trap_questions, 
                 success_strategies, recommended_answers, analysis_confidence, generated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                analysis.questionnaire_url,
                json.dumps(analysis.target_audience, ensure_ascii=False),
                json.dumps(analysis.question_patterns, ensure_ascii=False),
                json.dumps(analysis.trap_questions, ensure_ascii=False),
                json.dumps(analysis.success_strategies, ensure_ascii=False),
                json.dumps(analysis.recommended_answers, ensure_ascii=False),
                analysis.analysis_confidence,
                analysis.generated_at
            ))
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… é—®å·åˆ†æç»“æœå·²ä¿å­˜")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜é—®å·åˆ†æå¤±è´¥: {e}")
            return False
    
    async def get_questionnaire_analysis(self, questionnaire_url: str) -> Optional[QuestionnaireAnalysis]:
        """è·å–é—®å·åˆ†æç»“æœ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                SELECT * FROM questionnaire_analyses 
                WHERE questionnaire_url = ?
            ''', (questionnaire_url,))
            
            row = cursor.fetchone()
            conn.close()
            
            if not row:
                return None
            
            return QuestionnaireAnalysis(
                questionnaire_url=row[0],
                target_audience=json.loads(row[1]),
                question_patterns=json.loads(row[2]),
                trap_questions=json.loads(row[3]),
                success_strategies=json.loads(row[4]),
                recommended_answers=json.loads(row[5]),
                analysis_confidence=row[6],
                generated_at=row[7]
            )
            
        except Exception as e:
            logger.error(f"âŒ è·å–é—®å·åˆ†æå¤±è´¥: {e}")
            return None
    
    async def extract_experiences_from_scout_data(
        self, 
        questionnaire_url: str,
        scout_data: List[Dict]
    ) -> List[TemporaryExperience]:
        """ä»æ•¢æ­»é˜Ÿæ•°æ®ä¸­æå–ç»éªŒ"""
        experiences = []
        
        for scout in scout_data:
            scout_id = scout.get('scout_id', '')
            scout_name = scout.get('scout_name', '')
            pages = scout.get('pages', [])
            digital_human = scout.get('digital_human', {})
            
            for page in pages:
                page_number = page.get('page_number', 1)
                questions = page.get('questions_answered', [])
                success = page.get('success', False)
                
                for question in questions:
                    experience_id = f"exp_{int(time.time())}_{uuid.uuid4().hex[:8]}"
                    
                    experience = TemporaryExperience(
                        experience_id=experience_id,
                        questionnaire_url=questionnaire_url,
                        question_content=question.get('question', ''),
                        correct_answer=question.get('answer', ''),
                        wrong_answers=[],
                        answer_reasoning=question.get('reasoning', ''),
                        digital_human_id=scout_id,
                        digital_human_profile=digital_human,
                        success=success,
                        page_number=page_number,
                        timestamp=datetime.now().isoformat()
                    )
                    
                    experiences.append(experience)
                    await self.save_temporary_experience(experience)
        
        logger.info(f"âœ… ä»æ•¢æ­»é˜Ÿæ•°æ®ä¸­æå–äº† {len(experiences)} æ¡ç»éªŒ")
        return experiences
    
    async def generate_guidance_for_target_team(
        self, 
        questionnaire_url: str,
        target_digital_human: Dict
    ) -> str:
        """ä¸ºå¤§éƒ¨é˜Ÿæˆå‘˜ç”Ÿæˆæ™ºèƒ½æŒ‡å¯¼æç¤ºè¯"""
        
        # è·å–é—®å·åˆ†æç»“æœ
        analysis = await self.get_questionnaire_analysis(questionnaire_url)
        if not analysis:
            return self._generate_basic_guidance(target_digital_human)
        
        # è·å–ä¸´æ—¶ç»éªŒ
        temp_experiences = await self.get_temporary_experiences(questionnaire_url)
        successful_experiences = [exp for exp in temp_experiences if exp.success]
        
        # ç”Ÿæˆå®Œæ•´çš„æŒ‡å¯¼æç¤ºè¯
        guidance = f"""
ä½ æ˜¯{target_digital_human.get('name', 'æœªçŸ¥')}ï¼Œå¹´é¾„{target_digital_human.get('age', '30')}å²ï¼ŒèŒä¸šæ˜¯{target_digital_human.get('job', 'èŒå‘˜')}ï¼Œæœˆæ”¶å…¥{target_digital_human.get('income', '8000')}å…ƒã€‚

ğŸ¯ åŸºäºæ•¢æ­»é˜Ÿç»éªŒçš„æ™ºèƒ½æŒ‡å¯¼ï¼š

ğŸ“Š é—®å·ç›®æ ‡äººç¾¤åˆ†æï¼š
- å¹´é¾„èŒƒå›´ï¼š{analysis.target_audience.get('age_range', '25-35å²')}
- èŒä¸šç±»å‹ï¼š{', '.join(analysis.target_audience.get('occupation', ['åŠå…¬å®¤èŒå‘˜']))}
- æ”¶å…¥æ°´å¹³ï¼š{analysis.target_audience.get('income_level', 'ä¸­ç­‰')}

ğŸ§  æ™ºèƒ½ç­”é¢˜ç­–ç•¥ï¼š
"""
        
        for strategy in analysis.success_strategies:
            guidance += f"- {strategy}\n"
        
        if analysis.trap_questions:
            guidance += "\nâš ï¸ é™·é˜±é¢˜ç›®é¿å‘æŒ‡å—ï¼š\n"
            for trap in analysis.trap_questions:
                guidance += f"- {trap.get('question', '')}ï¼š{trap.get('correct_strategy', '')}\n"
        
        guidance += f"""

âœ… æ¨èç­”æ¡ˆæ¨¡å¼ï¼š
- å¹´é¾„åå¥½ï¼š{analysis.recommended_answers.get('age_preference', 'ä¸­ç­‰å¹´é¾„')}
- æ”¶å…¥åå¥½ï¼š{analysis.recommended_answers.get('income_preference', 'ä¸­ç­‰æ”¶å…¥')}
- èŒä¸šåå¥½ï¼š{analysis.recommended_answers.get('occupation_preference', 'ç¨³å®šèŒä¸š')}

ğŸ“‹ æ•¢æ­»é˜ŸæˆåŠŸç»éªŒï¼š
"""
        
        # æ·»åŠ å…·ä½“æˆåŠŸç»éªŒ
        for i, exp in enumerate(successful_experiences[:5], 1):
            guidance += f"""
ç»éªŒ{i}ï¼š{exp.digital_human_profile.get('name', 'æ•°å­—äºº')}çš„æˆåŠŸåšæ³•
- é¢˜ç›®ï¼š{exp.question_content[:100]}...
- ç­”æ¡ˆï¼š{exp.correct_answer}
- ç†ç”±ï¼š{exp.answer_reasoning}
"""
        
        guidance += f"""

ğŸ¯ ä½ çš„ä½œç­”è¦æ±‚ï¼š
1. ä¸¥æ ¼æŒ‰ç…§{target_digital_human.get('name', 'ä½ ')}çš„èº«ä»½ç‰¹å¾å›ç­”
2. å‚è€ƒä»¥ä¸ŠæˆåŠŸç»éªŒå’Œç­–ç•¥
3. é¿å…å·²çŸ¥çš„é™·é˜±é¢˜ç›®
4. é€‰æ‹©ç¬¦åˆç›®æ ‡äººç¾¤ç‰¹å¾çš„ç­”æ¡ˆ
5. å®Œæˆæ‰€æœ‰é¢˜ç›®ï¼Œç¡®ä¿100%ç­”é¢˜ç‡

åˆ†æå¯ä¿¡åº¦ï¼š{analysis.analysis_confidence:.1%}
        """
        
        return guidance.strip()
    
    def _generate_basic_guidance(self, target_digital_human: Dict) -> str:
        """ç”ŸæˆåŸºç¡€æŒ‡å¯¼ï¼ˆå½“æ²¡æœ‰åˆ†æç»“æœæ—¶ï¼‰"""
        return f"""
ä½ æ˜¯{target_digital_human.get('name', 'æœªçŸ¥')}ï¼Œå¹´é¾„{target_digital_human.get('age', '30')}å²ï¼ŒèŒä¸šæ˜¯{target_digital_human.get('job', 'èŒå‘˜')}ã€‚

è¯·æŒ‰ç…§ä½ çš„èº«ä»½ç‰¹å¾è®¤çœŸå›ç­”æ‰€æœ‰é—®é¢˜ï¼Œé€‰æ‹©æœ€ç¬¦åˆä½ ä¸ªäººæƒ…å†µçš„é€‰é¡¹ã€‚
        """
    
    async def cleanup_temporary_data(self, questionnaire_url: str) -> bool:
        """æ¸…ç†æŒ‡å®šé—®å·çš„ä¸´æ—¶æ•°æ®"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # æ¸…ç†ä¸´æ—¶ç»éªŒ
            cursor.execute('''
                DELETE FROM temporary_experiences 
                WHERE questionnaire_url = ?
            ''', (questionnaire_url,))
            
            # æ¸…ç†é—®å·åˆ†æ
            cursor.execute('''
                DELETE FROM questionnaire_analyses 
                WHERE questionnaire_url = ?
            ''', (questionnaire_url,))
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… å·²æ¸…ç†é—®å·ä¸´æ—¶æ•°æ®: {questionnaire_url}")
            return True
            
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ä¸´æ—¶æ•°æ®å¤±è´¥: {e}")
            return False

# å•ä¾‹æ¨¡å¼
_dual_kb_system = None

def get_dual_knowledge_base() -> DualKnowledgeBaseSystem:
    """è·å–åŒçŸ¥è¯†åº“ç³»ç»Ÿå•ä¾‹"""
    global _dual_kb_system
    if _dual_kb_system is None:
        _dual_kb_system = DualKnowledgeBaseSystem()
    return _dual_kb_system

# æµ‹è¯•ä»£ç 
async def test_dual_knowledge_base():
    """æµ‹è¯•åŒçŸ¥è¯†åº“ç³»ç»Ÿ"""
    kb = get_dual_knowledge_base()
    
    print("ğŸ§ª æµ‹è¯•åŒçŸ¥è¯†åº“ç³»ç»Ÿ")
    
    # æµ‹è¯•ä¸´æ—¶ç»éªŒä¿å­˜
    test_experience = TemporaryExperience(
        experience_id="test_exp_001",
        questionnaire_url="https://test.wjx.cn/test",
        question_content="æ‚¨çš„å¹´é¾„æ˜¯ï¼Ÿ",
        correct_answer="25-30å²",
        wrong_answers=[],
        answer_reasoning="ç¬¦åˆç›®æ ‡äººç¾¤",
        digital_human_id="dh_001",
        digital_human_profile={
            "name": "æµ‹è¯•å°é›…",
            "age": 28,
            "job": "äº§å“ç»ç†"
        },
        success=True,
        page_number=1,
        timestamp=datetime.now().isoformat()
    )
    
    success = await kb.save_temporary_experience(test_experience)
    print(f"ä¿å­˜ä¸´æ—¶ç»éªŒ: {'æˆåŠŸ' if success else 'å¤±è´¥'}")
    
    # æµ‹è¯•ç»éªŒæ£€ç´¢
    experiences = await kb.get_temporary_experiences("https://test.wjx.cn/test")
    print(f"æ£€ç´¢åˆ°ç»éªŒæ•°é‡: {len(experiences)}")
    
    # æµ‹è¯•é—®å·åˆ†æ
    analysis = await kb.analyze_questionnaire_with_gemini(
        "https://test.wjx.cn/test", experiences
    )
    print(f"é—®å·åˆ†æ: {'æˆåŠŸ' if analysis else 'å¤±è´¥'}")
    
    # æµ‹è¯•æŒ‡å¯¼ç”Ÿæˆ
    target_human = {
        "name": "æµ‹è¯•å°æ˜",
        "age": 30,
        "job": "è½¯ä»¶å·¥ç¨‹å¸ˆ",
        "income": "12000"
    }
    
    guidance = await kb.generate_guidance_for_target_team(
        "https://test.wjx.cn/test", target_human
    )
    print(f"æŒ‡å¯¼ç”Ÿæˆé•¿åº¦: {len(guidance)} å­—ç¬¦")
    
    # æ¸…ç†æµ‹è¯•æ•°æ®
    await kb.cleanup_temporary_data("https://test.wjx.cn/test")
    print("âœ… æµ‹è¯•å®Œæˆ")

if __name__ == "__main__":
    asyncio.run(test_dual_knowledge_base()) 