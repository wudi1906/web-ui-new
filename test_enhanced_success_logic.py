#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
æµ‹è¯•å¢å¼ºçš„æ•¢æ­»é˜ŸæˆåŠŸåˆ¤æ–­é€»è¾‘
åŸºäºç­”é¢˜æ•°é‡å’Œé”™è¯¯ç±»å‹çš„æ™ºèƒ½åˆ†ç±»
"""

import asyncio
import logging
from datetime import datetime
from typing import List, Dict

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# æ¨¡æ‹ŸScoutExperienceæ•°æ®ç»“æ„
class MockScoutExperience:
    def __init__(self, scout_name: str, questions_count: int, error_type: str = "none", 
                 technical_error_details: str = "", trap_triggered: bool = False):
        self.scout_id = f"scout_{scout_name.lower()}"
        self.scout_name = scout_name
        self.page_number = 1
        self.page_screenshot = ""
        self.page_content = f"{scout_name}çš„ç­”é¢˜å†…å®¹"
        self.questions_answered = [{"question": f"é¢˜ç›®{i+1}", "answer": f"é€‰é¡¹{i+1}"} for i in range(questions_count)]
        self.success = error_type in ["none", "normal_completion", "trap_termination"]
        self.failure_reason = technical_error_details if not self.success else None
        self.timestamp = datetime.now().isoformat()
        
        # æ–°å¢å­—æ®µ
        self.error_type = error_type
        self.questions_count = questions_count
        self.completion_depth = min(questions_count / 15, 1.0)
        self.trap_triggered = trap_triggered
        self.browser_error_displayed = error_type in ["code_error", "server_error", "api_error"]
        self.technical_error_details = technical_error_details

def analyze_scout_experiences(scout_experiences: List[MockScoutExperience]) -> Dict:
    """
    æ¨¡æ‹Ÿæ–°çš„æˆåŠŸåˆ¤æ–­é€»è¾‘æµ‹è¯•
    """
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•å¢å¼ºçš„æ•¢æ­»é˜ŸæˆåŠŸåˆ¤æ–­é€»è¾‘")
    logger.info("=" * 60)
    
    # æŒ‰ç…§ç”¨æˆ·éœ€æ±‚é‡æ–°åˆ†ç±»ç»éªŒ
    code_server_errors = []  # ä»£ç /æœåŠ¡å™¨é”™è¯¯
    normal_completion_experiences = []  # æ­£å¸¸ç­”é¢˜ç»éªŒï¼ˆåŒ…æ‹¬è¢«é™·é˜±é¢˜ç»ˆæ­¢ï¼‰
    
    for exp in scout_experiences:
        if exp.error_type in ["code_error", "server_error", "api_error"]:
            code_server_errors.append(exp)
            logger.warning(f"âš ï¸ å‘ç°æŠ€æœ¯é”™è¯¯: {exp.scout_name} - {exp.error_type}: {exp.technical_error_details}")
        else:
            # æ­£å¸¸ç­”é¢˜ç»éªŒï¼ˆåŒ…æ‹¬è¢«é™·é˜±é¢˜ç»ˆæ­¢çš„æƒ…å†µï¼‰
            normal_completion_experiences.append(exp)
    
    logger.info(f"ğŸ“Š ç»éªŒåˆ†ç±»ç»“æœ:")
    logger.info(f"   æŠ€æœ¯é”™è¯¯: {len(code_server_errors)} ä¸ª")
    logger.info(f"   æ­£å¸¸ç­”é¢˜: {len(normal_completion_experiences)} ä¸ª")
    
    # å¤„ç†æŠ€æœ¯é”™è¯¯
    if code_server_errors:
        logger.error(f"ğŸš¨ å‘ç° {len(code_server_errors)} ä¸ªæŠ€æœ¯é”™è¯¯ï¼Œéœ€è¦è°ƒè¯•:")
        for exp in code_server_errors:
            logger.error(f"   {exp.scout_name}: {exp.error_type} - {exp.technical_error_details}")
    
    # å¦‚æœæ²¡æœ‰æ­£å¸¸ç­”é¢˜ç»éªŒï¼Œæ— æ³•è¿›è¡Œåˆ†æ
    if len(normal_completion_experiences) == 0:
        logger.error(f"âŒ æ‰€æœ‰æ•¢æ­»é˜Ÿéƒ½é‡åˆ°æŠ€æœ¯é”™è¯¯ï¼Œæ— æ³•è¿›è¡Œæœ‰æ•ˆåˆ†æ")
        return {"analysis_possible": False, "reason": "all_technical_errors"}
    
    # æŒ‰ç­”é¢˜æ•°é‡æ’åºï¼Œç¡®å®š"ç›¸å¯¹æˆåŠŸ"çš„ç»éªŒ
    normal_completion_experiences.sort(key=lambda x: x.questions_count, reverse=True)
    
    # é€‰æ‹©ç­”é¢˜æ•°é‡æœ€å¤šçš„ç»éªŒä½œä¸º"æˆåŠŸ"ç»éªŒ
    max_questions = normal_completion_experiences[0].questions_count
    successful_experiences = [exp for exp in normal_completion_experiences if exp.questions_count == max_questions]
    failed_experiences = [exp for exp in normal_completion_experiences if exp.questions_count < max_questions]
    
    logger.info(f"ğŸ“Š æŒ‰ç­”é¢˜æ•°é‡åˆ†æç»“æœ:")
    logger.info(f"   æœ€å¤šç­”é¢˜æ•°é‡: {max_questions} é¢˜")
    logger.info(f"   æœ€æˆåŠŸç»éªŒ: {len(successful_experiences)} ä¸ª")
    logger.info(f"   ç›¸å¯¹å¤±è´¥ç»éªŒ: {len(failed_experiences)} ä¸ª")
    
    # æ˜¾ç¤ºè¯¦ç»†çš„ç­”é¢˜æƒ…å†µ
    for exp in successful_experiences:
        status = "ğŸ† æœ€æˆåŠŸ" if exp.questions_count == max_questions else "ğŸ“Š æ¬¡ä¼˜"
        trap_info = " (è§¦å‘é™·é˜±é¢˜)" if exp.trap_triggered else ""
        logger.info(f"   {status}: {exp.scout_name} - {exp.questions_count}é¢˜{trap_info}")
    
    # å¦‚æœæœ€å¤šç­”é¢˜æ•°é‡ä¸º0ï¼Œè¯´æ˜æ‰€æœ‰äººéƒ½æ— æ³•å¼€å§‹ç­”é¢˜
    if max_questions == 0:
        logger.error(f"âŒ æ‰€æœ‰æ•¢æ­»é˜Ÿç­”é¢˜æ•°é‡éƒ½ä¸º0ï¼Œå¯èƒ½å­˜åœ¨é¡µé¢åŠ è½½æˆ–é¢˜ç›®è¯†åˆ«é—®é¢˜")
        return {"analysis_possible": False, "reason": "zero_questions"}
    
    logger.info(f"âœ… åˆ†æå¯ä»¥ç»§ç»­ï¼ŒåŸºäº{len(successful_experiences)}ä¸ªæœ€æˆåŠŸç»éªŒ")
    
    return {
        "analysis_possible": True,
        "max_questions": max_questions,
        "successful_experiences": len(successful_experiences),
        "failed_experiences": len(failed_experiences),
        "technical_errors": len(code_server_errors),
        "most_successful_scouts": [exp.scout_name for exp in successful_experiences]
    }

async def test_scenario_1_mixed_results():
    """æµ‹è¯•åœºæ™¯1ï¼šæ··åˆç»“æœ - æœ‰æŠ€æœ¯é”™è¯¯ï¼Œæœ‰æ­£å¸¸ç­”é¢˜"""
    logger.info("\nğŸ§ª æµ‹è¯•åœºæ™¯1ï¼šæ··åˆç»“æœ")
    
    experiences = [
        MockScoutExperience("å¼ å°æ˜", 8, "normal_completion"),  # æ­£å¸¸å®Œæˆ8é¢˜
        MockScoutExperience("æå°çº¢", 5, "trap_termination", trap_triggered=True),  # é™·é˜±é¢˜ç»ˆæ­¢ï¼Œç­”äº†5é¢˜
        MockScoutExperience("ç‹å°å", 0, "api_error", "429 APIé…é¢è¶…é™"),  # APIé”™è¯¯
        MockScoutExperience("èµµå°æ•", 8, "normal_completion"),  # æ­£å¸¸å®Œæˆ8é¢˜
        MockScoutExperience("é™ˆå°å¼º", 0, "code_error", "ModuleNotFoundError: No module named 'xxx'")  # ä»£ç é”™è¯¯
    ]
    
    result = analyze_scout_experiences(experiences)
    logger.info(f"ğŸ¯ ç»“æœ: {result}")
    assert result["analysis_possible"] == True
    assert result["max_questions"] == 8
    assert result["most_successful_scouts"] == ["å¼ å°æ˜", "èµµå°æ•"]

async def test_scenario_2_all_technical_errors():
    """æµ‹è¯•åœºæ™¯2ï¼šå…¨éƒ¨æŠ€æœ¯é”™è¯¯"""
    logger.info("\nğŸ§ª æµ‹è¯•åœºæ™¯2ï¼šå…¨éƒ¨æŠ€æœ¯é”™è¯¯")
    
    experiences = [
        MockScoutExperience("å¼ å°æ˜", 0, "code_error", "è¯­æ³•é”™è¯¯"),
        MockScoutExperience("æå°çº¢", 0, "api_error", "ç½‘ç»œè¶…æ—¶"),
        MockScoutExperience("ç‹å°å", 0, "server_error", "æœåŠ¡å™¨500é”™è¯¯")
    ]
    
    result = analyze_scout_experiences(experiences)
    logger.info(f"ğŸ¯ ç»“æœ: {result}")
    assert result["analysis_possible"] == False
    assert result["reason"] == "all_technical_errors"

async def test_scenario_3_zero_questions():
    """æµ‹è¯•åœºæ™¯3ï¼šéƒ½æ— æ³•ç­”é¢˜"""
    logger.info("\nğŸ§ª æµ‹è¯•åœºæ™¯3ï¼šéƒ½æ— æ³•ç­”é¢˜")
    
    experiences = [
        MockScoutExperience("å¼ å°æ˜", 0, "normal_completion"),  # æ­£å¸¸ä½†ç­”é¢˜æ•°ä¸º0
        MockScoutExperience("æå°çº¢", 0, "trap_termination"),   # é™·é˜±é¢˜ä½†ç­”é¢˜æ•°ä¹Ÿä¸º0
    ]
    
    result = analyze_scout_experiences(experiences)
    logger.info(f"ğŸ¯ ç»“æœ: {result}")
    assert result["analysis_possible"] == False
    assert result["reason"] == "zero_questions"

async def test_scenario_4_trap_questions():
    """æµ‹è¯•åœºæ™¯4ï¼šé™·é˜±é¢˜æƒ…å†µ"""
    logger.info("\nğŸ§ª æµ‹è¯•åœºæ™¯4ï¼šé™·é˜±é¢˜æƒ…å†µ")
    
    experiences = [
        MockScoutExperience("å¼ å°æ˜", 12, "normal_completion"),  # æ­£å¸¸å®Œæˆ12é¢˜
        MockScoutExperience("æå°çº¢", 15, "normal_completion"),  # æ­£å¸¸å®Œæˆ15é¢˜ï¼ˆæœ€å¤šï¼‰
        MockScoutExperience("ç‹å°å", 8, "trap_termination", trap_triggered=True),  # é™·é˜±é¢˜ç»ˆæ­¢8é¢˜
        MockScoutExperience("èµµå°æ•", 15, "trap_termination", trap_triggered=True)   # é™·é˜±é¢˜ç»ˆæ­¢ä½†ç­”äº†15é¢˜
    ]
    
    result = analyze_scout_experiences(experiences)
    logger.info(f"ğŸ¯ ç»“æœ: {result}")
    assert result["analysis_possible"] == True
    assert result["max_questions"] == 15
    assert result["most_successful_scouts"] == ["æå°çº¢", "èµµå°æ•"]

async def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    logger.info("ğŸš€ å¼€å§‹æµ‹è¯•å¢å¼ºçš„æ•¢æ­»é˜ŸæˆåŠŸåˆ¤æ–­é€»è¾‘")
    logger.info("åŸºäºç­”é¢˜æ•°é‡å’Œé”™è¯¯ç±»å‹çš„æ™ºèƒ½åˆ†ç±»")
    logger.info("=" * 80)
    
    try:
        await test_scenario_1_mixed_results()
        await test_scenario_2_all_technical_errors()
        await test_scenario_3_zero_questions()
        await test_scenario_4_trap_questions()
        
        logger.info("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ–°çš„æˆåŠŸåˆ¤æ–­é€»è¾‘å·¥ä½œæ­£å¸¸")
        logger.info("ğŸ¯ æ ¸å¿ƒç‰¹ç‚¹ï¼š")
        logger.info("   1. æŠ€æœ¯é”™è¯¯ä¼šè¢«æ­£ç¡®è¯†åˆ«å’Œåˆ†ç±»")
        logger.info("   2. æŒ‰ç­”é¢˜æ•°é‡åˆ¤æ–­ç›¸å¯¹æˆåŠŸæ€§")
        logger.info("   3. é™·é˜±é¢˜ç»ˆæ­¢è¢«è§†ä¸ºæ­£å¸¸ç­”é¢˜")
        logger.info("   4. åªæœ‰åœ¨æœ‰æ­£å¸¸ç­”é¢˜ç»éªŒæ—¶æ‰è¿›è¡Œåˆ†æ")
        
    except Exception as e:
        logger.error(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(run_all_tests()) 